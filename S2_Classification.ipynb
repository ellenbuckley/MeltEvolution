{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6623a260",
   "metadata": {},
   "source": [
    "# Sentinel-2 Melt Pond Classification\n",
    "\n",
    "This program executes melt pond classification on imagery files processed from the previous scripts. The program outputs an HDF (.h5) file which will then be processed in the \"S2_Analysis\" script which will assess the numerical breakdown of each classification element. The HDF files may be converted as a .tif file and instructions are provided in the \"Useful_Assets\" script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio import mask\n",
    "import fiona\n",
    "from pylab import *\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f479c36",
   "metadata": {},
   "source": [
    "## The 'peakdet' Function\n",
    "\n",
    "The 'peakdet' function is used to set up histogram thresholds necessary to make the pixel-by-pixel classification. It is provided below to aid the classification methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peakdet(v, delta, x = None):\n",
    "    \n",
    "    maxtab = []\n",
    "    mintab = []\n",
    "       \n",
    "    if x is None:\n",
    "        x = np.arange(len(v))\n",
    "    \n",
    "    v = np.asarray(v)\n",
    "    \n",
    "    if len(v) != len(x):\n",
    "        sys.exit('Input vectors v and x must have same length')\n",
    "    \n",
    "    if not np.isscalar(delta):\n",
    "        sys.exit('Input argument delta must be a scalar')\n",
    "    \n",
    "    if delta <= 0:\n",
    "        sys.exit('Input argument delta must be positive')\n",
    "    \n",
    "    mn, mx = np.Inf, np.NINF\n",
    "    mnpos, mxpos = np.nan, np.nan\n",
    "    \n",
    "    lookformax = True\n",
    "   # mintab.append((0, 0.))\n",
    "    \n",
    "    for i in np.arange(len(v)):\n",
    "        this = v[i]\n",
    "        if this > mx:\n",
    "            mx = this\n",
    "            mxpos = x[i]\n",
    "        if this < mn:\n",
    "            mn = this\n",
    "            mnpos = x[i]\n",
    "        \n",
    "        if lookformax:\n",
    "            if this < mx-delta:\n",
    "                maxtab.append((mxpos, mx))\n",
    "                mn = this\n",
    "                mnpos = x[i]\n",
    "                lookformax = False\n",
    "        else:\n",
    "            if this > mn+delta:\n",
    "                mintab.append((mnpos, mn))\n",
    "                mx = this\n",
    "                mxpos = x[i]\n",
    "                lookformax = True\n",
    "    return np.array(maxtab), np.array(mintab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb21cc0",
   "metadata": {},
   "source": [
    "## Image Classification\n",
    "\n",
    "The image classification procedures are provided in one cell with in-line comments to aid users. The classification steps are briefly as follows:\n",
    "\n",
    "1. Reading in land masks to remove land pixels.\n",
    "2. Removing image border pixels.\n",
    "3. Seperating pixels between water and **not** water.\n",
    "4. Determining ice pixels.\n",
    "5. Seperating open water and melt pond pixels.\n",
    "6. Combining results into an HDF output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Reading in land masks to remove land pixels.\n",
    "\n",
    "# The 'landmask' directory provides shapefiles of Sentinel-2 tiles with land regions. Please take note of where\n",
    "# this directory is located in your local machine and make appropriate adjustments to the script. The tiles with\n",
    "# land pixels have been organized in a csv file named 'land_tiles.csv' and the script is designed to make appropriate\n",
    "# adjustments to files whose pathname includes these tiles. \n",
    "\n",
    "# Read the tile list for tiles with land in them. \n",
    "# Please make sure to change the file path below!\n",
    "land_tiles=pd.read_csv('/Volumes/Jaemin_IceDrive/MeltPonds/MeltEvolution/TestAssets/land_tiles.csv').tiles.values\n",
    "\n",
    "direc='/Volumes/Jaemin_IceDrive/MeltPonds/MeltEvolution/TestAssets/'\n",
    "\n",
    "# HDF Outputs will be saved in a seperate folder.\n",
    "if (os.path.exists(direc+'classification_hdf/')==False):\n",
    "    os.mkdir(direc+'classification_hdf/')\n",
    "\n",
    "    \n",
    "#store results\n",
    "f1=open(direc+'results.txt','a')\n",
    "# log errors\n",
    "log=open(direc+'errorlog.txt','a')\n",
    "\n",
    "\n",
    "# The following variable is the path of the base directory where the imagery files are located.\n",
    "# Please make sure to change the path based on your local machine. \n",
    "#direc='/Volumes/Jaemin_IceDrive/MeltPonds/MeltEvolution/TestAssets/'\n",
    "B02 = direc+ 'B02/'\n",
    "\n",
    "base_list = []\n",
    "for item in os.listdir(B02):\n",
    "    if \".jp2\" in item:\n",
    "        basefiles = item.split('_B02')[0]\n",
    "        base_list.append(basefiles)\n",
    "\n",
    "#print(baseitems)\n",
    "\n",
    "#base_list = np.unique(baseitems)\n",
    "\n",
    "\n",
    "for base in base_list:#[a[:-8] for a in os.listdir(direc+'B08/') if a.endswith('_B08.jp2')]:#['T08XNN_20200904T231129']:#T08XNH_20200930T210301']:#[a[:-8] for a in os.listdir(direc+'B08/') if a.endswith('_B08.jp2')][29:]:#['T14XMR_20200611T231131']: #['T20XNS_20200716T185921']:#[a[:-8] for a in os.listdir('.') if a.endswith('_B08.jp2')]:#[50:]:#['T14XNS_20200625T225121']:#['T10XES_20200626T231129']:#'T12XWP_20200727T224109']:# \n",
    "    yblue=base+'_B02.jp2'\n",
    "    ygreen=base+'_B03.jp2'\n",
    "    yred=base+'_B04.jp2'\n",
    "    ynir=base+'_B08.jp2'\n",
    "    \n",
    "    try:\n",
    "\n",
    "        imblue = rasterio.open(direc+'B02/'+yblue)#rasterio.open(direc+'B02/yes/'+yblue)\n",
    "        imgreen = rasterio.open(direc+'B03/'+ygreen)\n",
    "        imred = rasterio.open(direc+'B04/'+yred)\n",
    "        imnir = rasterio.open(direc+'B08/'+ynir)\n",
    "        \n",
    "\n",
    "        if base[:6] in land_tiles:\n",
    "            print('applying land mask to ' + base)\n",
    "            \n",
    "            # read in the land mask that is in the appropriate reference\n",
    "            with fiona.open(direc + \"landmask/arcticocean326\"+base[1:3]+\".shp\", \"r\") as shapefile:\n",
    "                geoms = [feature[\"geometry\"] for feature in shapefile]\n",
    "            \n",
    "            imblue_m = mask.mask(imblue, geoms, crop=True)\n",
    "            imgreen_m = mask.mask(imgreen, geoms, crop=True)\n",
    "            imred_m = mask.mask(imred, geoms, crop=True)\n",
    "            imnir_m = mask.mask(imnir, geoms, crop=True)\n",
    "\n",
    "            red=imred_m[0]\n",
    "            green=imgreen_m[0]\n",
    "            blue=imblue_m[0]\n",
    "            nir=imnir_m[0]\n",
    "\n",
    "            size_m=np.shape(red)\n",
    "            \n",
    "            sect_xmin,sect_xmax=0,size_m[1]\n",
    "            sect_ymin,sect_ymax=0,size_m[2]\n",
    "        else:\n",
    "            red=imred.read(1)\n",
    "            green=imgreen.read(1)\n",
    "            blue=imblue.read(1)\n",
    "            nir=imnir.read(1)\n",
    "            \n",
    "            size_m=np.shape(red)\n",
    "            \n",
    "            sect_xmin,sect_xmax=0,size_m[0]\n",
    "            sect_ymin,sect_ymax=0,size_m[1]\n",
    "\n",
    "\n",
    "        br1= np.divide((green.astype(float)-nir.astype(float)),(nir.astype(float)+green.astype(float)))\n",
    "\n",
    "        red_c=np.array(red,copy= True)\n",
    "        blue_c=np.array(blue,copy= True)\n",
    "        green_c=np.array(green,copy= True)\n",
    "        nir_c= np.array(nir,copy= True)\n",
    "\n",
    "#2. Removing image border pixels.\n",
    "#   Border Pixels are defined presently and subsequently removed later from the classification thresholds.\n",
    "        border=red_c<500\n",
    "\n",
    "#3. Seperating pixels between water and not water.\n",
    "        bins=np.arange(-.5,.5,.02)\n",
    "        Cbr1_n, bins= np.histogram(br1[sect_xmin:sect_xmax,sect_ymin:sect_ymax][~np.isnan(br1[sect_xmin:sect_xmax,sect_ymin:sect_ymax])&(~border[sect_xmin:sect_xmax,sect_ymin:sect_ymax])], bins)\n",
    "\n",
    "        dx= 0.0005*sum(Cbr1_n)  # dx is 0.05% difference\n",
    "        maxtab,mintab = peakdet(Cbr1_n,dx,x=None)\n",
    "\n",
    "        if np.where(Cbr1_n==max(Cbr1_n))[0][0]==maxtab[0][0]: # if there is only one max- do the fwhm to determine the cut\n",
    "            if maxtab[0,0]==0:\n",
    "                loc_cut=0\n",
    "            else:        \n",
    "                fwhm= np.min(np.where((bins[:-1]>bins[int(maxtab[0,0])]) & (Cbr1_n<(maxtab[0,1]/2.)))) # smaller bin value than max_x, smaller coutn than .5 max_y\n",
    "                loc_cut= int(maxtab[0,0]+ 2* (fwhm-maxtab[0,0])) # the cut location is 2* fwhm\n",
    "\n",
    "        else: #otherwise it is the minimum\n",
    "            loc_cut=int(mintab[np.where(maxtab[:,0]==np.where(Cbr1_n==max(Cbr1_n))[0][0])[0][0]-1,0])\n",
    "\n",
    "        if len(mintab)>0:\n",
    "            br1_cut =bins[int(mintab[-1,0])]\n",
    "        else:\n",
    "            br1_cut=bins[loc_cut]\n",
    "        water_mask=(br1>br1_cut)&(~border)\n",
    "\n",
    "\n",
    "# 4. Determining ice pixels.\n",
    "        binz=np.arange(0,10000,200)\n",
    "        n,bins=np.histogram(red_c[sect_xmin:sect_xmax,sect_ymin:sect_ymax][(~border[sect_xmin:sect_xmax,sect_ymin:sect_ymax])&(~water_mask[sect_xmin:sect_xmax,sect_ymin:sect_ymax])].flatten(),bins=binz)\n",
    "        dx= 0.0001*sum(n)  # dx is 0.01% difference\n",
    "        maxtab,mintab = peakdet(n,dx,x=None)\n",
    "        #print (maxtab, mintab)\n",
    "\n",
    "        if np.where(n==max(n))[0][0]==maxtab[0][0]: # if there is only one max or first max is highest\n",
    "            if maxtab[0,0]==0:\n",
    "                bin_cut=0\n",
    "            else:      \n",
    "                fwhm= np.max(np.where((bins[:-1]<bins[int(maxtab[0,0])]) & (n<(maxtab[0,1]/2.)))) # smaller bin value than max_x, smaller coutn than .5 max_y\n",
    "                bin_cut= int(maxtab[0,0]+ 2* (fwhm-maxtab[0,0])) # the cut location is 2* fwhm\n",
    "\n",
    "        else:\n",
    "            bin_cut=int(mintab[np.where(maxtab[:,0]==np.where(n==max(n))[0][0])[0][0]-1,0])\n",
    "\n",
    "        ice_cut=bins[bin_cut]\n",
    "\n",
    "        ice_mask=(red_c>ice_cut)&(~border)&(~water_mask)\n",
    "        other_mask=(red_c<=ice_cut)&(~border)&(~water_mask)\n",
    "\n",
    "\n",
    "#5. Seperating open water and melt pond pixels.\n",
    "        binz=np.arange(0,10000,200)\n",
    "    \n",
    "        n,bins=np.histogram(blue_c[(~ice_mask)&(~border)&(~other_mask)].flatten(),bins=binz)\n",
    "        dx= 0.0001*sum(n)  # dx is 0.01% difference\n",
    "        maxtab,mintab = peakdet(n,dx,x=None)\n",
    "\n",
    "        if (len(maxtab)>1):\n",
    "            if bins[int(mintab[-1,0])]>2000:\n",
    "                ow_cut=bins[int(mintab[-1,0])]\n",
    "            else:\n",
    "                n, bins= np.histogram(blue_c[water_mask], bins)\n",
    "                fwhm= np.min(np.where((bins[:-1]>bins[int(maxtab[-1,0])]) & (n<(maxtab[-1,1]/2.))))\n",
    "                loc_cut= int(maxtab[-1,0]+ 4* (fwhm-maxtab[-1,0]))\n",
    "                ow_cut=bins[loc_cut]\n",
    "\n",
    "        elif bins[int(maxtab[0,0])]<4000:\n",
    "            n, bins= np.histogram(blue_c[water_mask], bins)\n",
    "            fwhm= np.min(np.where((bins[:-1]>bins[int(maxtab[0,0])]) & (n<(maxtab[0,1]/2.))))\n",
    "            loc_cut= int(maxtab[0,0]+ 4* (fwhm-maxtab[0,0]))\n",
    "            ow_cut=bins[loc_cut]\n",
    "        else:\n",
    "            ow_cut=4000\n",
    "\n",
    "        ow_mask=(blue_c<ow_cut)&(water_mask)\n",
    "        mp_mask=(blue_c>=ow_cut)&(water_mask)\n",
    "\n",
    "# 6. Combining results into an HDF output.\n",
    "   # Before results can be exported, we want to take summary statistics of each defined class.\n",
    "        ow_pix=np.sum(ow_mask)\n",
    "        mp_pix=np.sum(mp_mask)\n",
    "        ice_pix=np.sum(ice_mask)\n",
    "        border_pix=np.sum(border)\n",
    "        other_pix=np.sum(other_mask)\n",
    "        im_pix= (sect_xmax-sect_xmin)*(sect_ymax-sect_ymin)\n",
    "\n",
    "        f1.write(base+'\\t'+str(im_pix)+'\\t'+str(border_pix)+'\\t'+str(ice_pix)+'\\t'+str(ow_pix)+'\\t'+str(mp_pix)+'\\t'+str(other_pix)+'\\n')\n",
    "\n",
    "\n",
    "        # Check sum for pixels\n",
    "        # If pixels don't sum to 1, this means that there was some error or misclassification.\n",
    "        pixel_sum = (1 * border + 1 * ice_mask + 1 * ow_mask + 1 * mp_mask + 1 * other_mask)\n",
    "        if (~np.all(pixel_sum == 1)):\n",
    "            log.write(\"Sum pixels not 1 {0}: {1}\\n\".format(str(base), str(e)))\n",
    "\n",
    "        # Calculated Parameters\n",
    "        MPF=np.nan\n",
    "        SIC=np.round((mp_pix+ice_pix)/np.float32(ice_pix+mp_pix+ow_pix)*100,2)\n",
    "        if SIC>15:\n",
    "            MPF=np.round((mp_pix)/np.float32(ice_pix+mp_pix)*100,2)\n",
    "\n",
    "        #Set up dataset for hdf5 files\n",
    "        classification = np.zeros_like(border, dtype=np.int8)    # 8 bit int\n",
    "        classification += (1 * ice_mask + 2 * ow_mask + 3 * mp_mask + 4 * other_mask)\n",
    "\n",
    "        fout_name = direc+'classification_hdf/{}_classification.h5'.format(base)\n",
    "        with h5py.File(fout_name, \"w\") as fout:\n",
    "            fout.attrs[\"title\"] = \"Classification of Sentinel-2 Sea Ice Summer Melt Features\"\n",
    "            fout.attrs[\"creator_email\"] = \"buckley@umd.edu\"\n",
    "\n",
    "            fout.attrs[\"references\"] = \"Buckley, E. M., Farrell, S. L., Herzfeld, U. C., Webster, M., Trantow, T., Baney, O. N., Duncan, K., Han, H., Lawson, M. (2023). Observing the Evolution of Summer Melt on Multiyear Sea Ice with ICESat-2 and Sentinel-2 [Manuscript in Preparation].\"\n",
    "            fout.attrs[\"source_image\"] = base\n",
    "            fout.attrs[\"MPF (%)\"] = MPF\n",
    "            fout.attrs[\"SIC (%)\"] = SIC\n",
    "\n",
    "\n",
    "            dset = fout.create_dataset(\"classification\", data=classification,\n",
    "                    compression=\"gzip\")\n",
    "            dset.attrs[\"categories\"] = \"0 border, 1 ice, 2 open water, 3 melt pond, 4 other\"\n",
    "        \n",
    "               \n",
    "        \n",
    "    except Exception as e:\n",
    "        log.write(\"Failed to process {0}: {1}\\n\".format(str(base), str(e)))\n",
    "    finally:\n",
    "        pass\n",
    "    \n",
    "f1.close()\n",
    "log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf315e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
